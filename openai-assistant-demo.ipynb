{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that you may not have to run the command here, if you already have openai SDK installed\n",
    "# Upgrade to \n",
    "# Python SDK v1.2\n",
    "# with \n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "\n",
    "# Import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(api_key)\n",
    "openai.api_key = api_key#os.environ[\"OPENAI_API_KEY\"]  # Set your OpenAI API key\n",
    "print (openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "  # api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create an Assistant\n",
    "An Assistant represents an entity that can be configured to respond to usersâ€™ Messages using several parameters like:\n",
    "\n",
    "Instructions: how the Assistant and model should behave or respond\n",
    "\n",
    "Model: you can specify any GPT-3.5 or GPT-4 models, including fine-tuned models. \n",
    "\n",
    "Tools: the API supports Code Interpreter and Retrieval that are built and hosted by OpenAI.\n",
    "\n",
    "Functions: the API allows you to define custom function signatures, with similar behavior as our function calling feature.\n",
    "\n",
    "In this example, we're following the [Assistants API Overview (Python SDK)](https://cookbook.openai.com/examples/assistants_api_overview_python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a Thread\n",
    "\n",
    "A Thread represents a conversation. We recommend creating one Thread per user as soon as the user initiates the conversation. Pass any user-specific context and files in this thread by creating Messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add a Message to a Thread\n",
    "A Message contains text, and optionally any files that you allow the user to upload. Messages need to be added to a specific Thread. Adding images via message objects like in Chat Completions using GPT-4 with Vision is not supported today, but we plan to add support for them in the coming months. You can still upload images and have them processes via retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    ")\n",
    "\n",
    "print(\"Run completed with status: \" + run.status)\n",
    "\n",
    "if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "    print(\"messages: \")\n",
    "    for message in messages:\n",
    "        assert message.content[0].type == \"text\"\n",
    "        print({\"role\": message.role, \"message\": message.content[0].text.value})\n",
    "\n",
    "    client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-demo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
